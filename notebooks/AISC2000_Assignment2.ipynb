{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa0389db-0e32-4a1e-86e4-1fda43373d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sspc1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sspc1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fc27d0a-542b-4c1d-bb3d-922b27028970",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3082291816.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[71], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install emoji\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5933c6e2-8dea-4c83-b8b1-7435f48b4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordsegment\n",
      "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Downloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
      "   ---------------------------------------- 0.0/4.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.8 MB 653.6 kB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.2/4.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/4.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.9/4.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.4/4.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.1/4.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.1/4.8 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.5/4.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.5/4.8 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.6/4.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.8/4.8 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: wordsegment\n",
      "Successfully installed wordsegment-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordsegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1a91d-91f0-406a-beb7-b37f7175a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10bdd7d2-315b-4527-9163-07cf5287f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading using chunk size\n",
    "\n",
    "reviews = pd.read_json('yelp_dataset/yelp_academic_dataset_review.json', lines=True, chunksize=20000)\n",
    "\n",
    "# Iterate through chunks and process each one\n",
    "chunk_list = []\n",
    "for chunk in reviews:\n",
    "    chunk_list.append(chunk)\n",
    "    \n",
    "# Concatenate the chunks after reading\n",
    "reviews_df = pd.concat(chunk_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c992a0-3261-4e3f-a280-517300386025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text                date  \n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3528142-1685-4bcb-a308-cea6cc04e991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6990280, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17ec16dc-f826-4da5-b4b8-ec469b39ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6990280 entries, 0 to 6990279\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   review_id    object        \n",
      " 1   user_id      object        \n",
      " 2   business_id  object        \n",
      " 3   stars        int64         \n",
      " 4   useful       int64         \n",
      " 5   funny        int64         \n",
      " 6   cool         int64         \n",
      " 7   text         object        \n",
      " 8   date         datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(4), object(4)\n",
      "memory usage: 480.0+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bf49c4c-e012-4c4b-9bf7-01a6a8101096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "user_id        0\n",
       "business_id    0\n",
       "stars          0\n",
       "useful         0\n",
       "funny          0\n",
       "cool           0\n",
       "text           0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8fda9-a574-4003-aa21-d205111bb645",
   "metadata": {},
   "source": [
    "# Target Variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9e32a73-2abb-4760-b0b3-e1a1fdce1d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18   \n",
       "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30   \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03   \n",
       "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15   \n",
       "\n",
       "  sentiment  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating the target variable (Positive, Negative, Neutral)\n",
    "def label_review(stars):\n",
    "    if stars >= 4:\n",
    "        return '1'   # positive\n",
    "    elif stars <= 2:\n",
    "        return '-1'  # negative\n",
    "    else:\n",
    "        return '0'   # Neutral\n",
    "\n",
    "\n",
    "reviews_df['sentiment'] = reviews_df['stars'].apply(label_review)\n",
    "\n",
    "reviews_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91aecb-27f7-4fdb-84b3-3104d7e78f6e",
   "metadata": {},
   "source": [
    "# Preprocessing the 'text' columns\n",
    "1. lowercasing\n",
    "2. removing punctuation\n",
    "3. Removing stop words\n",
    "4. Negation handling  - Not, No, Never, None, n't\n",
    "5. Expanding Contractions\n",
    "6. Handling abbrevations\n",
    "7. removing emojis and hashtags\n",
    "8. Tokenization\n",
    "9. Stemming - reducing the word to base form\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376aad8d-7b60-4397-8ae7-f78fed5ea4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data size: (209708, 10)\n"
     ]
    }
   ],
   "source": [
    "# Sampling 3% of the data\n",
    "sampled_reviews = reviews_df.sample(frac=0.03, random_state=42)  \n",
    "\n",
    "\n",
    "print(f\"Sampled data size: {sampled_reviews.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e64d4f4f-1e70-468f-924c-f86d6827b8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>neg_handled_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1295256</th>\n",
       "      <td>J5Q1gH4ACCj6CtQG7Yom7g</td>\n",
       "      <td>56gL9KEJNHiSDUoyjk2o3Q</td>\n",
       "      <td>8yR12PNSMo6FBYx1u5KPlw</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went for lunch and found that my burger was me...</td>\n",
       "      <td>2018-04-04 21:09:53</td>\n",
       "      <td>-1</td>\n",
       "      <td>went lunch found burger meh obviou focu burger...</td>\n",
       "      <td>went lunch found burger meh obviou focu burger...</td>\n",
       "      <td>went lunch found burger meh obviou focu burger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297618</th>\n",
       "      <td>HlXP79ecTquSVXmjM10QxQ</td>\n",
       "      <td>bAt9OUFX9ZRgGLCXG22UmA</td>\n",
       "      <td>pBNucviUkNsiqhJv5IFpjg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I needed a new tires for my wife's car. They h...</td>\n",
       "      <td>2020-05-24 12:22:14</td>\n",
       "      <td>1</td>\n",
       "      <td>need new tire wife car special order next day ...</td>\n",
       "      <td>need new tire wife car special order next day ...</td>\n",
       "      <td>need new tire wife car special order next day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217795</th>\n",
       "      <td>JBBULrjyGx6vHto2osk_CQ</td>\n",
       "      <td>NRHPcLq2vGWqgqwVugSgnQ</td>\n",
       "      <td>8sf9kv6O4GgEb0j1o22N1g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jim Woltman who works at Goleta Honda is 5 sta...</td>\n",
       "      <td>2019-02-14 03:47:48</td>\n",
       "      <td>1</td>\n",
       "      <td>jim woltman work goleta honda 5 star knowledg ...</td>\n",
       "      <td>jim woltman work goleta honda 5 star knowledg ...</td>\n",
       "      <td>jim woltman work goleta honda 5 star knowledg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730348</th>\n",
       "      <td>U9-43s8YUl6GWBFCpxUGEw</td>\n",
       "      <td>PAxc0qpqt5c2kA0rjDFFAg</td>\n",
       "      <td>XwepyB7KjJ-XGJf0vKc6Vg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Been here a few times to get some shrimp.  The...</td>\n",
       "      <td>2013-04-27 01:55:49</td>\n",
       "      <td>1</td>\n",
       "      <td>time get shrimp theyv got nice select differ f...</td>\n",
       "      <td>time get shrimp theyv got nice select differ f...</td>\n",
       "      <td>time get shrimp got nice select differ fish pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826590</th>\n",
       "      <td>8T8EGa_4Cj12M6w8vRgUsQ</td>\n",
       "      <td>BqPR1Dp5Rb_QYs9_fz9RiA</td>\n",
       "      <td>prm5wvpp0OHJBlrvTj9uOg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is one fantastic place to eat whether you...</td>\n",
       "      <td>2019-05-15 18:29:25</td>\n",
       "      <td>1</td>\n",
       "      <td>one fantast place eat whether hungri need good...</td>\n",
       "      <td>one fantast place eat whether hungri need good...</td>\n",
       "      <td>one fantast place eat whether hungri need good...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "1295256  J5Q1gH4ACCj6CtQG7Yom7g  56gL9KEJNHiSDUoyjk2o3Q   \n",
       "3297618  HlXP79ecTquSVXmjM10QxQ  bAt9OUFX9ZRgGLCXG22UmA   \n",
       "1217795  JBBULrjyGx6vHto2osk_CQ  NRHPcLq2vGWqgqwVugSgnQ   \n",
       "3730348  U9-43s8YUl6GWBFCpxUGEw  PAxc0qpqt5c2kA0rjDFFAg   \n",
       "1826590  8T8EGa_4Cj12M6w8vRgUsQ  BqPR1Dp5Rb_QYs9_fz9RiA   \n",
       "\n",
       "                    business_id  stars  useful  funny  cool  \\\n",
       "1295256  8yR12PNSMo6FBYx1u5KPlw      2       1      0     0   \n",
       "3297618  pBNucviUkNsiqhJv5IFpjg      5       0      0     0   \n",
       "1217795  8sf9kv6O4GgEb0j1o22N1g      5       0      0     0   \n",
       "3730348  XwepyB7KjJ-XGJf0vKc6Vg      4       0      0     0   \n",
       "1826590  prm5wvpp0OHJBlrvTj9uOg      5       0      0     0   \n",
       "\n",
       "                                                      text  \\\n",
       "1295256  Went for lunch and found that my burger was me...   \n",
       "3297618  I needed a new tires for my wife's car. They h...   \n",
       "1217795  Jim Woltman who works at Goleta Honda is 5 sta...   \n",
       "3730348  Been here a few times to get some shrimp.  The...   \n",
       "1826590  This is one fantastic place to eat whether you...   \n",
       "\n",
       "                       date sentiment  \\\n",
       "1295256 2018-04-04 21:09:53        -1   \n",
       "3297618 2020-05-24 12:22:14         1   \n",
       "1217795 2019-02-14 03:47:48         1   \n",
       "3730348 2013-04-27 01:55:49         1   \n",
       "1826590 2019-05-15 18:29:25         1   \n",
       "\n",
       "                                                clean_text  \\\n",
       "1295256  went lunch found burger meh obviou focu burger...   \n",
       "3297618  need new tire wife car special order next day ...   \n",
       "1217795  jim woltman work goleta honda 5 star knowledg ...   \n",
       "3730348  time get shrimp theyv got nice select differ f...   \n",
       "1826590  one fantast place eat whether hungri need good...   \n",
       "\n",
       "                                          neg_handled_text  \\\n",
       "1295256  went lunch found burger meh obviou focu burger...   \n",
       "3297618  need new tire wife car special order next day ...   \n",
       "1217795  jim woltman work goleta honda 5 star knowledg ...   \n",
       "3730348  time get shrimp theyv got nice select differ f...   \n",
       "1826590  one fantast place eat whether hungri need good...   \n",
       "\n",
       "                                        final_cleaned_text  \n",
       "1295256  went lunch found burger meh obviou focu burger...  \n",
       "3297618  need new tire wife car special order next day ...  \n",
       "1217795  jim woltman work goleta honda 5 star knowledg ...  \n",
       "3730348  time get shrimp got nice select differ fish pr...  \n",
       "1826590  one fantast place eat whether hungri need good...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordsegment import load, segment\n",
    "import contractions  \n",
    "import abbr  \n",
    "\n",
    "\n",
    "load()\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "\n",
    "def clean_hashtags(text):\n",
    "    \n",
    "    hashtags = re.findall(r'#\\w+', text)\n",
    "    for hashtag in hashtags:\n",
    "        words = ' '.join(segment(hashtag[1:]))  \n",
    "        text = text.replace(hashtag, words)\n",
    "    return text\n",
    "\n",
    "def handle_negation(text):\n",
    "    \n",
    "    negation_patterns = re.compile(r'\\b(?:not|no|never|none|n\\'t)\\b[\\w\\s]+[^\\w\\s]')\n",
    "    return negation_patterns.sub(lambda match: '_'.join(match.group(0).split()), text)\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Expanding contractions\n",
    "    text = expand_contractions(text)\n",
    "    \n",
    "\n",
    "    # negation\n",
    "    text = handle_negation(text)\n",
    "\n",
    "    # hashtags\n",
    "    text = clean_hashtags(text)\n",
    "\n",
    "    # emojis\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    # punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sampled_reviews['final_cleaned_text'] = sampled_reviews['text'].apply(clean_text)\n",
    "\n",
    "\n",
    "\n",
    "sampled_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85240da8-1109-4189-8948-492e0bf52d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a24b0f0-86a5-47f2-bd1b-a1bab60508cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>neg_handled_text</th>\n",
       "      <th>final_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J5Q1gH4ACCj6CtQG7Yom7g</td>\n",
       "      <td>56gL9KEJNHiSDUoyjk2o3Q</td>\n",
       "      <td>8yR12PNSMo6FBYx1u5KPlw</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went for lunch and found that my burger was me...</td>\n",
       "      <td>2018-04-04 21:09:53</td>\n",
       "      <td>-1</td>\n",
       "      <td>went lunch found burger meh obviou focu burger...</td>\n",
       "      <td>went lunch found burger meh obviou focu burger...</td>\n",
       "      <td>went lunch found burger meh obviou focu burger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HlXP79ecTquSVXmjM10QxQ</td>\n",
       "      <td>bAt9OUFX9ZRgGLCXG22UmA</td>\n",
       "      <td>pBNucviUkNsiqhJv5IFpjg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I needed a new tires for my wife's car. They h...</td>\n",
       "      <td>2020-05-24 12:22:14</td>\n",
       "      <td>1</td>\n",
       "      <td>need new tire wife car special order next day ...</td>\n",
       "      <td>need new tire wife car special order next day ...</td>\n",
       "      <td>need new tire wife car special order next day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JBBULrjyGx6vHto2osk_CQ</td>\n",
       "      <td>NRHPcLq2vGWqgqwVugSgnQ</td>\n",
       "      <td>8sf9kv6O4GgEb0j1o22N1g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jim Woltman who works at Goleta Honda is 5 sta...</td>\n",
       "      <td>2019-02-14 03:47:48</td>\n",
       "      <td>1</td>\n",
       "      <td>jim woltman work goleta honda 5 star knowledg ...</td>\n",
       "      <td>jim woltman work goleta honda 5 star knowledg ...</td>\n",
       "      <td>jim woltman work goleta honda 5 star knowledg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U9-43s8YUl6GWBFCpxUGEw</td>\n",
       "      <td>PAxc0qpqt5c2kA0rjDFFAg</td>\n",
       "      <td>XwepyB7KjJ-XGJf0vKc6Vg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Been here a few times to get some shrimp.  The...</td>\n",
       "      <td>2013-04-27 01:55:49</td>\n",
       "      <td>1</td>\n",
       "      <td>time get shrimp theyv got nice select differ f...</td>\n",
       "      <td>time get shrimp theyv got nice select differ f...</td>\n",
       "      <td>time get shrimp got nice select differ fish pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8T8EGa_4Cj12M6w8vRgUsQ</td>\n",
       "      <td>BqPR1Dp5Rb_QYs9_fz9RiA</td>\n",
       "      <td>prm5wvpp0OHJBlrvTj9uOg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is one fantastic place to eat whether you...</td>\n",
       "      <td>2019-05-15 18:29:25</td>\n",
       "      <td>1</td>\n",
       "      <td>one fantast place eat whether hungri need good...</td>\n",
       "      <td>one fantast place eat whether hungri need good...</td>\n",
       "      <td>one fantast place eat whether hungri need good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18E_haOfOm8ks-A7SlVWRg</td>\n",
       "      <td>bnDZpsii_if2_wpn8oPcig</td>\n",
       "      <td>bK0j7YtVyN98UnM_8fUONg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dirt cheap happy hour specials.  Half priced d...</td>\n",
       "      <td>2011-11-08 01:30:27</td>\n",
       "      <td>0</td>\n",
       "      <td>dirt cheap happi hour special half price drink...</td>\n",
       "      <td>dirt cheap happi hour special half price drink...</td>\n",
       "      <td>dirt cheap happi hour special half price drink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8rD5LvgHVPSnyyae4ji4dA</td>\n",
       "      <td>YxpJDf6Idn7MA9E003B0Zw</td>\n",
       "      <td>zLIrhVc1nfPTOF33eFD4_g</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Unbelievably poor customer \"service\".  Beyond ...</td>\n",
       "      <td>2011-05-15 22:58:44</td>\n",
       "      <td>-1</td>\n",
       "      <td>unbeliev poor custom servic beyond bad insist ...</td>\n",
       "      <td>unbeliev poor custom servic beyond bad insist ...</td>\n",
       "      <td>unbeliev poor custom servic beyond bad insist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hYYN8bWKRW29qqdpaKOdMg</td>\n",
       "      <td>8H183Gq4be1PqKBW7jbIiA</td>\n",
       "      <td>KHl171eshtTPrGyBWGEHQQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I walked in the door and was greeted with a we...</td>\n",
       "      <td>2015-05-24 11:48:33</td>\n",
       "      <td>1</td>\n",
       "      <td>walk door greet welcom smile offer help find g...</td>\n",
       "      <td>walk door greet welcom smile offer help find g...</td>\n",
       "      <td>walk door greet welcom smile offer help find g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xQVDB9xRdpLmPh9XMQ6Gvg</td>\n",
       "      <td>yy38DH7ENFTJ10-d4GUlig</td>\n",
       "      <td>S26FJcC298XNpN2cZiwOrA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nothing beats pizza and beer in my book. This ...</td>\n",
       "      <td>2012-12-24 02:18:18</td>\n",
       "      <td>1</td>\n",
       "      <td>noth beat pizza beer book place nail eye towar...</td>\n",
       "      <td>noth beat pizza beer book place nail eye towar...</td>\n",
       "      <td>noth beat pizza beer book place nail eye towar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c7IQ5alG0pl9yCITtsIlrA</td>\n",
       "      <td>ZLKpeCqbCMWfNeT6yU8wUQ</td>\n",
       "      <td>zT2OzXDWKK1abapHs2RUrQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Philly cheese steak (loaded)  was phenomenal. ...</td>\n",
       "      <td>2021-07-02 02:17:40</td>\n",
       "      <td>1</td>\n",
       "      <td>philli chees steak load phenomen good servic v...</td>\n",
       "      <td>philli chees steak load phenomen good servic v...</td>\n",
       "      <td>philli chees steak load phenomen good servic v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  J5Q1gH4ACCj6CtQG7Yom7g  56gL9KEJNHiSDUoyjk2o3Q  8yR12PNSMo6FBYx1u5KPlw   \n",
       "1  HlXP79ecTquSVXmjM10QxQ  bAt9OUFX9ZRgGLCXG22UmA  pBNucviUkNsiqhJv5IFpjg   \n",
       "2  JBBULrjyGx6vHto2osk_CQ  NRHPcLq2vGWqgqwVugSgnQ  8sf9kv6O4GgEb0j1o22N1g   \n",
       "3  U9-43s8YUl6GWBFCpxUGEw  PAxc0qpqt5c2kA0rjDFFAg  XwepyB7KjJ-XGJf0vKc6Vg   \n",
       "4  8T8EGa_4Cj12M6w8vRgUsQ  BqPR1Dp5Rb_QYs9_fz9RiA  prm5wvpp0OHJBlrvTj9uOg   \n",
       "5  18E_haOfOm8ks-A7SlVWRg  bnDZpsii_if2_wpn8oPcig  bK0j7YtVyN98UnM_8fUONg   \n",
       "6  8rD5LvgHVPSnyyae4ji4dA  YxpJDf6Idn7MA9E003B0Zw  zLIrhVc1nfPTOF33eFD4_g   \n",
       "7  hYYN8bWKRW29qqdpaKOdMg  8H183Gq4be1PqKBW7jbIiA  KHl171eshtTPrGyBWGEHQQ   \n",
       "8  xQVDB9xRdpLmPh9XMQ6Gvg  yy38DH7ENFTJ10-d4GUlig  S26FJcC298XNpN2cZiwOrA   \n",
       "9  c7IQ5alG0pl9yCITtsIlrA  ZLKpeCqbCMWfNeT6yU8wUQ  zT2OzXDWKK1abapHs2RUrQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      2       1      0     0   \n",
       "1      5       0      0     0   \n",
       "2      5       0      0     0   \n",
       "3      4       0      0     0   \n",
       "4      5       0      0     0   \n",
       "5      3       1      1     1   \n",
       "6      1       4      1     0   \n",
       "7      5       1      0     0   \n",
       "8      5       0      0     0   \n",
       "9      5       1      0     0   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  Went for lunch and found that my burger was me... 2018-04-04 21:09:53   \n",
       "1  I needed a new tires for my wife's car. They h... 2020-05-24 12:22:14   \n",
       "2  Jim Woltman who works at Goleta Honda is 5 sta... 2019-02-14 03:47:48   \n",
       "3  Been here a few times to get some shrimp.  The... 2013-04-27 01:55:49   \n",
       "4  This is one fantastic place to eat whether you... 2019-05-15 18:29:25   \n",
       "5  Dirt cheap happy hour specials.  Half priced d... 2011-11-08 01:30:27   \n",
       "6  Unbelievably poor customer \"service\".  Beyond ... 2011-05-15 22:58:44   \n",
       "7  I walked in the door and was greeted with a we... 2015-05-24 11:48:33   \n",
       "8  Nothing beats pizza and beer in my book. This ... 2012-12-24 02:18:18   \n",
       "9  Philly cheese steak (loaded)  was phenomenal. ... 2021-07-02 02:17:40   \n",
       "\n",
       "  sentiment                                         clean_text  \\\n",
       "0        -1  went lunch found burger meh obviou focu burger...   \n",
       "1         1  need new tire wife car special order next day ...   \n",
       "2         1  jim woltman work goleta honda 5 star knowledg ...   \n",
       "3         1  time get shrimp theyv got nice select differ f...   \n",
       "4         1  one fantast place eat whether hungri need good...   \n",
       "5         0  dirt cheap happi hour special half price drink...   \n",
       "6        -1  unbeliev poor custom servic beyond bad insist ...   \n",
       "7         1  walk door greet welcom smile offer help find g...   \n",
       "8         1  noth beat pizza beer book place nail eye towar...   \n",
       "9         1  philli chees steak load phenomen good servic v...   \n",
       "\n",
       "                                    neg_handled_text  \\\n",
       "0  went lunch found burger meh obviou focu burger...   \n",
       "1  need new tire wife car special order next day ...   \n",
       "2  jim woltman work goleta honda 5 star knowledg ...   \n",
       "3  time get shrimp theyv got nice select differ f...   \n",
       "4  one fantast place eat whether hungri need good...   \n",
       "5  dirt cheap happi hour special half price drink...   \n",
       "6  unbeliev poor custom servic beyond bad insist ...   \n",
       "7  walk door greet welcom smile offer help find g...   \n",
       "8  noth beat pizza beer book place nail eye towar...   \n",
       "9  philli chees steak load phenomen good servic v...   \n",
       "\n",
       "                                  final_cleaned_text  \n",
       "0  went lunch found burger meh obviou focu burger...  \n",
       "1  need new tire wife car special order next day ...  \n",
       "2  jim woltman work goleta honda 5 star knowledg ...  \n",
       "3  time get shrimp got nice select differ fish pr...  \n",
       "4  one fantast place eat whether hungri need good...  \n",
       "5  dirt cheap happi hour special half price drink...  \n",
       "6  unbeliev poor custom servic beyond bad insist ...  \n",
       "7  walk door greet welcom smile offer help find g...  \n",
       "8  noth beat pizza beer book place nail eye towar...  \n",
       "9  philli chees steak load phenomen good servic v...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62599bed-03a4-4860-828f-bc52fe90a088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209708, 13)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6bc463-d4b3-4f8b-be2f-8bf5619b849c",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbbbaa46-d4d8-43e9-9c2b-b37b94d6b2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "1     112467\n",
      "-1     38654\n",
      "0      16645\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sampled_reviews['final_cleaned_text'], sampled_reviews['sentiment'], test_size=0.2, stratify=sampled_reviews['sentiment'], random_state=42)\n",
    "\n",
    "\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "feb5f58d-1d5f-41c4-8e38-bed1c2ef8f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181428    best pizza st pete opinion kind upset took lon...\n",
       "32644     first thing need know pinewood social extrem i...\n",
       "55173     food pretti good got meal grill beyond eat not...\n",
       "204776    flowmast 44 put charger right bought figur bou...\n",
       "73757     got number 11 omg sam made tast differ 30 year...\n",
       "Name: final_cleaned_text, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df0f52-056d-4d15-9368-e156acf54616",
   "metadata": {},
   "source": [
    "# saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c077325d-1eec-4c9d-b178-f7a6d5cd4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv( 'x_train_ml2',index=False)\n",
    "y_train.to_csv( 'y_train_ml2',index=False)\n",
    "x_test.to_csv('x_test_ml2',index=False)\n",
    "y_test.to_csv('y_test_ml2',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb274bb8-02b1-4c81-82e3-27fa9aaeaffc",
   "metadata": {},
   "source": [
    "# Vectorization -  Unigram Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57785c92-f12f-4bfd-9041-52c5640d343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_vectorizer_unigram = CountVectorizer(ngram_range=(1, 1), max_features=5000, max_df=0.9,min_df=5)\n",
    "\n",
    "\n",
    "x_train_count_unigram = count_vectorizer_unigram.fit_transform(x_train)\n",
    "x_test_count_unigram = count_vectorizer_unigram.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc7a1daf-c5f2-45e4-87dc-1295ee901ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167766, 5000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_count_unigram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84224f0f-1293-484a-a133-515c20c1fd13",
   "metadata": {},
   "source": [
    "# One-Hot Unigram Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e163f8a-264c-4460-9940-30fe94e91515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_hot_vectorizer_unigram = CountVectorizer(ngram_range=(1, 1), binary=True,max_features=5000)\n",
    "\n",
    "\n",
    "x_train_onehot_unigram = one_hot_vectorizer_unigram.fit_transform(x_train)\n",
    "x_test_onehot_unigram = one_hot_vectorizer_unigram.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2b0c5-2981-4dff-a92c-28b0e25d5df7",
   "metadata": {},
   "source": [
    "# Class separability check on Unigram Count vectorizer - below cell still need to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145e0f3-9bd0-4e8f-9b61-addc8b18d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ipca = IncrementalPCA(n_components=2)\n",
    "\n",
    "\n",
    "batch_size = 10000 \n",
    "for i in range(0, x_train_count_unigram.shape[0], batch_size):\n",
    "    ipca.partial_fit(x_train_count_unigram[i:i + batch_size].toarray())\n",
    "\n",
    "\n",
    "x_train_pca = ipca.transform(x_train_count_unigram.toarray())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=y_train, cmap='viridis', alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.title('Class Separability Check using Incremental PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16906c1c-c5f6-447f-ae8c-cd0ac1479fa5",
   "metadata": {},
   "source": [
    "# Numerical Features\n",
    "1. Cool\n",
    "2. useful\n",
    "\n",
    "# Run below cell after vectorization for adding above mentioned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "57b850eb-2134-49d5-9e4f-2658a2753b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "x_train_combined = hstack([\n",
    "    x_train_count_unigram,\n",
    "    sampled_reviews.loc[x_train.index, ['useful', 'cool']].values\n",
    "])\n",
    "\n",
    "x_test_combined = hstack([\n",
    "    x_test_count_unigram,\n",
    "    sampled_reviews.loc[x_test.index, ['useful', 'cool']].values\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bb478816-8611-40ef-99e2-d191f472af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559222, 5002)\n",
      "(139806, 5002)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_combined.shape)\n",
    "print(x_test_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7718f-5b46-488e-a70d-8194ff2f79c0",
   "metadata": {},
   "source": [
    "\n",
    "# 1.Before Splitting data\n",
    "\n",
    " 1. Data loading and initial exploration\n",
    " 2. Sampled 3% of data \n",
    " 3. Data cleaning (handling of negations, stop words, stemming, contractions)\n",
    "\n",
    "  \n",
    "\n",
    "# 2.Train and Test Split\n",
    "\n",
    "# 3.Vectorization \n",
    "Did\n",
    "1. Unigram count vectorization\n",
    "2. please apply different vectorization techniques according to your tasks and assignment.\n",
    "\n",
    "\n",
    "# 3.Class Separability \n",
    "- pending\n",
    "\n",
    "\n",
    "# 4.Numerical Features Added\n",
    "\n",
    "1. cool\n",
    "2. useful\n",
    "\n",
    "\n",
    "# 5.Feature Set with Best Separability\n",
    "\n",
    "Needs to be decided after implementing step 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa38d0e-aaf4-42ff-a5a8-e0e427d70b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
